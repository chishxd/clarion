"""
This type stub file was generated by pyright.
"""

from .logger import Logger

"""
A context object for caching a function's return value each time it
is called with the same input arguments.

"""
FIRST_LINE_TEXT = ...
def extract_first_line(func_code): # -> tuple[str | Any, int]:
    """Extract the first line information from the function code
    text if available.
    """
    ...

class JobLibCollisionWarning(UserWarning):
    """Warn that there might be a collision between names of functions."""
    ...


_STORE_BACKENDS = ...
def register_store_backend(backend_name, backend): # -> None:
    """Extend available store backends.

    The Memory, MemorizeResult and MemorizeFunc objects are designed to be
    agnostic to the type of store used behind. By default, the local file
    system is used but this function gives the possibility to extend joblib's
    memory pattern with other types of storage such as cloud storage (S3, GCS,
    OpenStack, HadoopFS, etc) or blob DBs.

    Parameters
    ----------
    backend_name: str
        The name identifying the store backend being registered. For example,
        'local' is used with FileSystemStoreBackend.
    backend: StoreBackendBase subclass
        The name of a class that implements the StoreBackendBase interface.

    """
    ...

_FUNCTION_HASHES = ...
class MemorizedResult(Logger):
    """Object representing a cached value.

    Attributes
    ----------
    location: str
        The location of joblib cache. Depends on the store backend used.

    func: function or str
        function whose output is cached. The string case is intended only for
        instantiation based on the output of repr() on another instance.
        (namely eval(repr(memorized_instance)) works).

    argument_hash: str
        hash of the function arguments.

    backend: str
        Type of store backend for reading/writing cache files.
        Default is 'local'.

    mmap_mode: {None, 'r+', 'r', 'w+', 'c'}
        The memmapping mode used when loading from cache numpy arrays. See
        numpy.load for the meaning of the different values.

    verbose: int
        verbosity level (0 means no message).

    timestamp, metadata: string
        for internal use only.
    """
    def __init__(self, location, call_id, backend=..., mmap_mode=..., verbose=..., timestamp=..., metadata=...) -> None:
        ...
    
    @property
    def func(self):
        ...
    
    @property
    def func_id(self):
        ...
    
    @property
    def args_id(self):
        ...
    
    def get(self): # -> Any:
        """Read value from cache and return it."""
        ...
    
    def clear(self): # -> None:
        """Clear value from cache"""
        ...
    
    def __repr__(self): # -> str:
        ...
    
    def __getstate__(self): # -> dict[str, Any]:
        ...
    


class NotMemorizedResult:
    """Class representing an arbitrary value.

    This class is a replacement for MemorizedResult when there is no cache.
    """
    __slots__ = ...
    def __init__(self, value) -> None:
        ...
    
    def get(self): # -> Any | None:
        ...
    
    def clear(self): # -> None:
        ...
    
    def __repr__(self): # -> str:
        ...
    
    def __getstate__(self): # -> dict[str, Any]:
        ...
    
    def __setstate__(self, state): # -> None:
        ...
    


class NotMemorizedFunc:
    """No-op object decorating a function.

    This class replaces MemorizedFunc when there is no cache. It provides an
    identical API but does not write anything on disk.

    Attributes
    ----------
    func: callable
        Original undecorated function.
    """
    def __init__(self, func) -> None:
        ...
    
    def __call__(self, *args, **kwargs):
        ...
    
    def call_and_shelve(self, *args, **kwargs): # -> NotMemorizedResult:
        ...
    
    def __repr__(self): # -> str:
        ...
    
    def clear(self, warn=...): # -> None:
        ...
    
    def call(self, *args, **kwargs): # -> tuple[Any, dict[Any, Any]]:
        ...
    
    def check_call_in_cache(self, *args, **kwargs): # -> Literal[False]:
        ...
    


class AsyncNotMemorizedFunc(NotMemorizedFunc):
    async def call_and_shelve(self, *args, **kwargs): # -> NotMemorizedResult:
        ...
    


class MemorizedFunc(Logger):
    """Callable object decorating a function for caching its return value
    each time it is called.

    Methods are provided to inspect the cache or clean it.

    Attributes
    ----------
    func: callable
        The original, undecorated, function.

    location: string
        The location of joblib cache. Depends on the store backend used.

    backend: str
        Type of store backend for reading/writing cache files.
        Default is 'local', in which case the location is the path to a
        disk storage.

    ignore: list or None
        List of variable names to ignore when choosing whether to
        recompute.

    mmap_mode: {None, 'r+', 'r', 'w+', 'c'}
        The memmapping mode used when loading from cache
        numpy arrays. See numpy.load for the meaning of the different
        values.

    compress: boolean, or integer
        Whether to zip the stored data on disk. If an integer is
        given, it should be between 1 and 9, and sets the amount
        of compression. Note that compressed arrays cannot be
        read by memmapping.

    verbose: int, optional
        The verbosity flag, controls messages that are issued as
        the function is evaluated.

    cache_validation_callback: callable, optional
        Callable to check if a result in cache is valid or is to be recomputed.
        When the function is called with arguments for which a cache exists,
        the callback is called with the cache entry's metadata as its sole
        argument. If it returns True, the cached result is returned, else the
        cache for these arguments is cleared and the result is recomputed.
    """
    def __init__(self, func, location, backend=..., ignore=..., mmap_mode=..., compress=..., verbose=..., timestamp=..., cache_validation_callback=...) -> None:
        ...
    
    @property
    def func_code_info(self): # -> tuple[str, str | Any, int] | tuple[str, Any, Any] | tuple[str, Any | str | None, Literal[-1]]:
        ...
    
    def call_and_shelve(self, *args, **kwargs): # -> MemorizedResult | Any:
        """Call wrapped function, cache result and return a reference.

        This method returns a reference to the cached result instead of the
        result itself. The reference object is small and picklable, allowing
        to send or store it easily. Call .get() on reference object to get
        result.

        Returns
        -------
        cached_result: MemorizedResult or NotMemorizedResult
            reference to the value returned by the wrapped function. The
            class "NotMemorizedResult" is used when there is no cache
            activated (e.g. location=None in Memory).
        """
        ...
    
    def __call__(self, *args, **kwargs): # -> MemorizedResult | Any:
        ...
    
    def __getstate__(self): # -> dict[str, Any]:
        ...
    
    def check_call_in_cache(self, *args, **kwargs): # -> bool:
        """Check if the function call is cached and valid for given arguments.

        Does not call the function or do any work besides function inspection
        and argument hashing.

        - Compare the function code with the one from the cached function,
          asserting if it has changed.
        - Check if the function call is present in the cache.
        - Call `cache_validation_callback` for user define cache validation.

        Returns
        -------
        is_call_in_cache: bool
            Whether or not the function call is in cache and can be used.
        """
        ...
    
    def clear(self, warn=...): # -> None:
        """Empty the function's cache."""
        ...
    
    def call(self, *args, **kwargs): # -> tuple[MemorizedResult, dict[str, Any]] | tuple[Any, dict[str, Any]]:
        """Force the execution of the function with the given arguments.

        The output values will be persisted, i.e., the cache will be updated
        with any new values.

        Parameters
        ----------
        *args: arguments
            The arguments.
        **kwargs: keyword arguments
            Keyword arguments.

        Returns
        -------
        output : object
            The output of the function call.
        metadata : dict
            The metadata associated with the call.
        """
        ...
    
    def __repr__(self): # -> str:
        ...
    


class AsyncMemorizedFunc(MemorizedFunc):
    async def __call__(self, *args, **kwargs): # -> Any | MemorizedResult:
        ...
    
    async def call_and_shelve(self, *args, **kwargs): # -> Any | MemorizedResult:
        ...
    
    async def call(self, *args, **kwargs): # -> Any | tuple[MemorizedResult, dict[str, Any]] | tuple[Any, dict[str, Any]]:
        ...
    


class Memory(Logger):
    """A context object for caching a function's return value each time it
    is called with the same input arguments.

    All values are cached on the filesystem, in a deep directory
    structure.

    Read more in the :ref:`User Guide <memory>`.

    Parameters
    ----------
    location: str, pathlib.Path or None
        The path of the base directory to use as a data store
        or None. If None is given, no caching is done and
        the Memory object is completely transparent. This option
        replaces cachedir since version 0.12.

    backend: str, optional, default='local'
        Type of store backend for reading/writing cache files.
        The 'local' backend is using regular filesystem operations to
        manipulate data (open, mv, etc) in the backend.

    mmap_mode: {None, 'r+', 'r', 'w+', 'c'}, optional
        The memmapping mode used when loading from cache
        numpy arrays. See numpy.load for the meaning of the
        arguments.

    compress: boolean, or integer, optional
        Whether to zip the stored data on disk. If an integer is
        given, it should be between 1 and 9, and sets the amount
        of compression. Note that compressed arrays cannot be
        read by memmapping.

    verbose: int, optional
        Verbosity flag, controls the debug messages that are issued
        as functions are evaluated.

    backend_options: dict, optional
        Contains a dictionary of named parameters used to configure
        the store backend.
    """
    def __init__(self, location=..., backend=..., mmap_mode=..., compress=..., verbose=..., backend_options=...) -> None:
        ...
    
    def cache(self, func=..., ignore=..., verbose=..., mmap_mode=..., cache_validation_callback=...): # -> partial[Any] | AsyncNotMemorizedFunc | NotMemorizedFunc | AsyncMemorizedFunc | MemorizedFunc:
        """Decorates the given function func to only compute its return
        value for input arguments not cached on disk.

        Parameters
        ----------
        func: callable, optional
            The function to be decorated
        ignore: list of strings
            A list of arguments name to ignore in the hashing
        verbose: integer, optional
            The verbosity mode of the function. By default that
            of the memory object is used.
        mmap_mode: {None, 'r+', 'r', 'w+', 'c'}, optional
            The memmapping mode used when loading from cache
            numpy arrays. See numpy.load for the meaning of the
            arguments. By default that of the memory object is used.
        cache_validation_callback: callable, optional
            Callable to validate whether or not the cache is valid. When
            the cached function is called with arguments for which a cache
            exists, this callable is called with the metadata of the cached
            result as its sole argument. If it returns True, then the
            cached result is returned, else the cache for these arguments
            is cleared and recomputed.

        Returns
        -------
        decorated_func: MemorizedFunc object
            The returned object is a MemorizedFunc object, that is
            callable (behaves like a function), but offers extra
            methods for cache lookup and management. See the
            documentation for :class:`joblib.memory.MemorizedFunc`.
        """
        ...
    
    def clear(self, warn=...): # -> None:
        """Erase the complete cache directory."""
        ...
    
    def reduce_size(self, bytes_limit=..., items_limit=..., age_limit=...): # -> None:
        """Remove cache elements to make the cache fit its limits.

        The limitation can impose that the cache size fits in ``bytes_limit``,
        that the number of cache items is no more than ``items_limit``, and
        that all files in cache are not older than ``age_limit``.

        Parameters
        ----------
        bytes_limit: int | str, optional
            Limit in bytes of the size of the cache. By default, the size of
            the cache is unlimited. When reducing the size of the cache,
            ``joblib`` keeps the most recently accessed items first. If a
            str is passed, it is converted to a number of bytes using units
            { K | M | G} for kilo, mega, giga.

        items_limit: int, optional
            Number of items to limit the cache to.  By default, the number of
            items in the cache is unlimited.  When reducing the size of the
            cache, ``joblib`` keeps the most recently accessed items first.

        age_limit: datetime.timedelta, optional
            Maximum age of items to limit the cache to.  When reducing the size
            of the cache, any items last accessed more than the given length of
            time ago are deleted. Example: to remove files older than 5 days,
            use datetime.timedelta(days=5). Negative timedelta are not
            accepted.
        """
        ...
    
    def eval(self, func, *args, **kwargs): # -> CoroutineType[Any, Any, Any | MemorizedResult] | MemorizedResult | Any:
        """Eval function func with arguments `*args` and `**kwargs`,
        in the context of the memory.

        This method works similarly to the builtin `apply`, except
        that the function is called only if the cache is not
        up to date.

        """
        ...
    
    def __repr__(self): # -> str:
        ...
    
    def __getstate__(self): # -> dict[str, Any]:
        """We don't store the timestamp when pickling, to avoid the hash
        depending from it.
        """
        ...
    


def expires_after(days=..., seconds=..., microseconds=..., milliseconds=..., minutes=..., hours=..., weeks=...): # -> Callable[..., Any]:
    """Helper cache_validation_callback to force recompute after a duration.

    Parameters
    ----------
    days, seconds, microseconds, milliseconds, minutes, hours, weeks: numbers
        argument passed to a timedelta.
    """
    ...

